{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca84e61a-4071-4ff2-949e-b09caab7cf69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(20000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 20 seconds\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%autosave 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b1cee0f-f0ce-4027-96d2-52e4c6a43c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a871af-6628-4bea-a0b3-5bd21127606b",
   "metadata": {},
   "source": [
    "# Input Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "095dc308-6f24-4558-bab5-7bc53e35db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbeddings(nn.Module):\n",
    "    def __init__(self, d_model: int, vocab_size: int) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model # Dimention of model\n",
    "        self.vocab_size = vocab_size  # total number of Words in the Input\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (batch, seq_len) --> (batch, seq_len, d_model)\n",
    "        # Multiply by sqrt(d_model) to scale the embeddings according to the paper\n",
    "        return self.embedding(x) , math.sqrt(self.d_model) , self.embedding(x)*math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ee1fcc5-5a2d-4aa4-8eb0-3fef51049c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "seq_len = 5\n",
    "d_model = 16\n",
    "vocab_size = 100\n",
    "\n",
    "x = torch.randint(0, vocab_size, (batch_size, seq_len))\n",
    "embeddings = InputEmbeddings(d_model, vocab_size)\n",
    "output_emb = embeddings(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6152a1e3-f1a1-4141-b532-79715093eaba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1d0a0f5-dfb2-4e41-98b5-6f72b06fb13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_emb[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41c6ab0d-335c-433b-a8e3-71547cb5a54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_emb[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49cff509-a9d3-453c-9ab2-18ff482ab7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.5196e+00,  3.5437e+00,  5.4313e-01,  1.9134e+00, -1.2026e+00,\n",
       "           8.1953e+00, -1.6043e+00,  6.1331e-01, -2.8480e+00, -1.2120e+00,\n",
       "          -1.4446e+00, -1.0584e-02,  1.6469e+00,  3.9262e+00, -1.5580e+00,\n",
       "           4.3438e-01],\n",
       "         [ 5.1470e+00, -1.1315e-01, -5.3884e+00, -1.3013e+00, -1.4926e+00,\n",
       "           2.4929e+00,  2.5210e+00,  4.1980e-01, -5.1099e-02,  1.9285e+00,\n",
       "           1.2127e+00,  3.2001e+00,  4.0178e+00,  1.2280e+00,  4.3481e+00,\n",
       "           1.2110e+00],\n",
       "         [-1.2578e+01,  2.2901e+00, -3.3737e-01, -2.1863e+00, -1.7225e+00,\n",
       "          -2.7290e+00, -1.6102e+00, -2.7874e+00,  3.1315e+00, -2.7698e+00,\n",
       "          -7.6416e-01, -4.0520e+00,  3.0876e+00,  5.4205e+00, -4.5514e+00,\n",
       "           5.5078e+00],\n",
       "         [-1.9107e-01,  6.0942e+00, -3.4973e+00, -1.3215e+00,  3.7744e-01,\n",
       "          -2.0132e+00, -1.6465e+00,  3.9348e+00, -4.4714e+00, -8.2981e+00,\n",
       "          -1.6041e+00, -8.9192e-01, -1.8988e+00,  1.9794e+00, -9.0373e+00,\n",
       "           1.8060e+00],\n",
       "         [ 1.3132e+00,  8.5649e-01,  5.3424e+00, -2.6089e+00,  3.0883e+00,\n",
       "          -7.7729e+00, -7.2914e-01,  6.7284e+00, -3.4225e+00, -3.6740e-01,\n",
       "          -1.8436e+00,  2.8670e+00, -1.9738e+00,  1.1016e-01, -1.1600e+00,\n",
       "           2.8307e-01]],\n",
       "\n",
       "        [[-1.1831e+00,  6.0196e+00,  1.9772e+00,  1.1722e+00,  5.9433e+00,\n",
       "           4.0409e+00, -2.0102e+00, -1.7054e-01, -4.5686e+00, -5.2602e+00,\n",
       "          -4.8592e-01,  3.2596e+00,  1.1483e+00,  1.2776e+01,  1.8681e+00,\n",
       "           2.7594e+00],\n",
       "         [-1.3392e+00,  4.6848e+00,  1.9126e+00, -6.4846e+00,  4.2423e+00,\n",
       "           3.5323e+00, -2.0201e+00, -3.5581e+00,  1.6172e-01,  1.0081e+01,\n",
       "          -3.2161e+00,  6.1490e-02,  1.3177e+00, -1.5945e+00,  6.0389e+00,\n",
       "          -4.5261e+00],\n",
       "         [-3.0275e+00,  7.7659e+00, -1.3871e+00,  1.3410e-02,  3.0091e+00,\n",
       "          -5.5531e+00, -1.5794e+00,  3.3084e+00, -1.0630e+00, -2.3945e+00,\n",
       "          -3.8204e+00,  3.9530e+00, -3.3187e+00,  6.2591e-01, -3.5218e+00,\n",
       "          -5.3726e+00],\n",
       "         [ 1.4053e-01,  7.2515e+00, -5.5686e-01,  2.2420e-01,  2.1630e+00,\n",
       "           8.2610e-01, -3.9242e+00, -4.2530e+00, -5.0218e+00, -2.3140e+00,\n",
       "          -1.8869e+00,  1.8350e+00, -3.7024e-01,  1.0475e+00, -3.1144e+00,\n",
       "           9.6636e-01],\n",
       "         [ 1.7992e-01, -1.1584e+00,  8.6049e-01,  6.8176e+00, -8.7121e+00,\n",
       "           1.7305e+00, -2.6105e+00,  2.9248e-01,  3.7839e+00, -5.9823e-01,\n",
       "           3.4230e+00, -1.7427e+00, -4.5926e+00,  4.0865e+00,  1.5102e+00,\n",
       "          -4.6265e+00]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_emb[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339861b3-ac63-4962-bc2e-3010edc2aed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687f9613-07d1-407e-86b3-90f706900f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e808b63c-5932-45c4-945e-de5c9f9b438c",
   "metadata": {},
   "source": [
    "# Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479c2ef6-ae91-44db-b428-a18e943f0144",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, seq_len: int, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Create a matrix of shape (seq_len, d_model)\n",
    "        pe = torch.zeros(seq_len, d_model)\n",
    "        # Create a vector of shape (seq_len)\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1) # (seq_len, 1)\n",
    "        # Create a vector of shape (d_model)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) # (d_model / 2)\n",
    "        # Apply sine to even indices\n",
    "        pe[:, 0::2] = torch.sin(position * div_term) # sin(position * (10000 ** (2i / d_model))\n",
    "        # Apply cosine to odd indices\n",
    "        pe[:, 1::2] = torch.cos(position * div_term) # cos(position * (10000 ** (2i / d_model))\n",
    "        # Add a batch dimension to the positional encoding\n",
    "        pe = pe.unsqueeze(0) # (1, seq_len, d_model)\n",
    "        # Register the positional encoding as a buffer\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False) # (batch, seq_len, d_model)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2c136f-3994-4f0e-a4c8-1a531e26c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 16\n",
    "seq_len = 5\n",
    "dropout = 0.1\n",
    "pos_encoding = PositionalEncoding(d_model, seq_len, dropout)\n",
    "\n",
    "# Create a sample input tensor (batch_size, seq_len, d_model)\n",
    "batch_size = 2\n",
    "x = torch.randn(batch_size, seq_len, d_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cc10df3-625a-499d-a5c1-cc9e37d34c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = torch.zeros(seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69c369fd-8741-4831-bebb-ccaac413d28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe[:, 0::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37784545-d94c-46a0-9ac0-84a0afb0f9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe[:, 1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb577b6a-8177-4e5e-ba8e-2d4d5f007f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40441ea1-2542-49d8-995b-163e44b7a42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e18d0f3c-52e2-4be6-a822-f7d52d2e953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "140c3e0a-67be-4bb0-be93-e589fe18e310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 3.1623e-01, 1.0000e-01, 3.1623e-02, 1.0000e-02, 3.1623e-03,\n",
       "        1.0000e-03, 3.1623e-04])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e52d997e-b85c-4151-92e6-3db852afb09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f4d0fe-a938-45b8-892c-b1fba8d46f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_emb[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618542a6-3dff-4d3e-9fb6-4e113bf68670",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Forward pass\n",
    "output_pos_emb = pos_encoding(output_emb[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c3c913-4d62-4618-81c0-5645ed177641",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pos_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762d64ee-4301-4018-846a-14ea0a6fae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pos_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f451ae92-c1ae-4406-af30-a68a952a95de",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df973302-0fae-45f8-90e3-09875f5fd4c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

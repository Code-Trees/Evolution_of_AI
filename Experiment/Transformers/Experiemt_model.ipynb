{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca84e61a-4071-4ff2-949e-b09caab7cf69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(20000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 20 seconds\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%autosave 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b1cee0f-f0ce-4027-96d2-52e4c6a43c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9271275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "seq_len = 16\n",
    "d_model = 8\n",
    "vocab_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a871af-6628-4bea-a0b3-5bd21127606b",
   "metadata": {},
   "source": [
    "# Input Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "095dc308-6f24-4558-bab5-7bc53e35db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbeddings(nn.Module):\n",
    "    def __init__(self, d_model: int, vocab_size: int) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model # Dimention of model\n",
    "        self.vocab_size = vocab_size  # total number of Words in the Input\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (batch, seq_len) --> (batch, seq_len, d_model)\n",
    "        # Multiply by sqrt(d_model) to scale the embeddings according to the paper\n",
    "        return self.embedding(x)*math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74a7f150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[45, 10, 47, 10,  1, 85, 94, 84,  7, 57, 56, 90, 88, 26, 82, 70],\n",
       "        [74, 16, 34, 68, 93, 68, 88, 45, 54, 93, 76, 65, 35, 70, 72, 10],\n",
       "        [71, 46, 96, 30, 70, 47, 23, 47, 35, 24, 80, 91, 29, 41, 53, 19],\n",
       "        [21, 82, 24, 74, 70, 60, 57, 52,  9, 66, 98, 53, 16, 80,  5, 59]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(0,vocab_size,(batch_size,seq_len))\n",
    "x.shape\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b901c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.0857,  2.5561, -1.5502,  4.6947,  2.7813,  1.6331,  3.3028,\n",
       "          -1.7598],\n",
       "         [-0.4488, -2.3459,  0.1917, -2.5710, -5.4087, -0.9784,  2.5236,\n",
       "           2.5344],\n",
       "         [-0.5505,  0.2772,  1.8915,  6.7931,  2.9333, -2.7175, -5.6576,\n",
       "           4.5879],\n",
       "         [-0.4488, -2.3459,  0.1917, -2.5710, -5.4087, -0.9784,  2.5236,\n",
       "           2.5344],\n",
       "         [-1.7179,  6.2368, -3.7011, -1.4160,  0.6128, -2.5922,  1.8761,\n",
       "           3.8129],\n",
       "         [ 4.5298,  0.4563,  2.1949,  2.5172, -0.1886,  0.5180,  1.7574,\n",
       "           3.7915],\n",
       "         [ 1.3536,  4.3405,  1.1270,  0.1371, -1.5373,  1.4282, -6.5935,\n",
       "          -0.8932],\n",
       "         [ 1.0093, -7.3339,  3.7362, -0.4357, -1.0572,  2.8729, -4.1980,\n",
       "           6.2552],\n",
       "         [ 1.6804,  2.9969,  0.3324,  0.1212, -0.5262, -1.2266, -1.4652,\n",
       "          -2.2411],\n",
       "         [ 4.2105,  4.4562,  0.9855,  5.0401,  2.8744, -2.0868, -0.9742,\n",
       "           1.2223],\n",
       "         [ 2.9400,  1.3464,  0.3139, -0.6258, -2.9078, -1.7433,  1.2947,\n",
       "          -3.1989],\n",
       "         [ 1.0585,  0.0589,  2.3406, -6.0528, -3.4200,  0.3548,  1.1832,\n",
       "          -1.6679],\n",
       "         [ 3.3194, -3.4343, -0.2380,  0.4132, -0.3406, -2.3228,  0.8111,\n",
       "           4.3222],\n",
       "         [ 4.7825, -6.2904,  1.9847,  4.8815, -1.9982, -2.2607, -2.2209,\n",
       "          -3.9247],\n",
       "         [-1.0859,  0.1397,  2.4643, -4.6394, -2.2958,  3.8204, -0.8981,\n",
       "          -0.5112],\n",
       "         [ 0.7326,  1.1572,  4.9376, -6.6083, -0.6134,  2.1168, -3.0200,\n",
       "           1.2251]],\n",
       "\n",
       "        [[ 2.0418, -1.3944,  3.5376,  7.9463,  0.2721, -2.8114, -0.3941,\n",
       "           1.1258],\n",
       "         [-2.2435, -3.4456, -7.0729,  2.5914, -2.7787, -0.1917, -2.3160,\n",
       "          -1.4080],\n",
       "         [ 0.9244,  3.6094, -3.8738, -2.5462, -0.0377, -0.7265, -1.5263,\n",
       "          -1.3537],\n",
       "         [-1.5205, -2.3901,  0.5394, -5.6503, -3.6762,  2.6759, -5.3543,\n",
       "           4.0166],\n",
       "         [ 0.8324,  1.1745,  1.7066,  2.3083, -4.0565,  3.3772, -2.5294,\n",
       "          -1.2468],\n",
       "         [-1.5205, -2.3901,  0.5394, -5.6503, -3.6762,  2.6759, -5.3543,\n",
       "           4.0166],\n",
       "         [ 3.3194, -3.4343, -0.2380,  0.4132, -0.3406, -2.3228,  0.8111,\n",
       "           4.3222],\n",
       "         [-3.0857,  2.5561, -1.5502,  4.6947,  2.7813,  1.6331,  3.3028,\n",
       "          -1.7598],\n",
       "         [ 2.8952,  2.1427,  3.9056,  3.9822,  4.9735,  2.1923, -2.7753,\n",
       "          -0.2031],\n",
       "         [ 0.8324,  1.1745,  1.7066,  2.3083, -4.0565,  3.3772, -2.5294,\n",
       "          -1.2468],\n",
       "         [-1.4130, -2.8273,  3.8674, -1.2894,  0.9216,  2.0653,  2.4598,\n",
       "          -0.5029],\n",
       "         [-6.5500, -1.7530, -0.9431,  2.1763,  7.3778, -2.3174, -1.7764,\n",
       "           6.0569],\n",
       "         [-4.7788, -2.8521,  4.9142, -2.7896,  0.6033, -4.6777, -1.3862,\n",
       "          -1.7100],\n",
       "         [ 0.7326,  1.1572,  4.9376, -6.6083, -0.6134,  2.1168, -3.0200,\n",
       "           1.2251],\n",
       "         [ 1.7200,  2.3449,  0.9281,  1.3838,  5.7667, -1.5952,  0.1524,\n",
       "          -1.2004],\n",
       "         [-0.4488, -2.3459,  0.1917, -2.5710, -5.4087, -0.9784,  2.5236,\n",
       "           2.5344]],\n",
       "\n",
       "        [[ 1.8339,  2.2800, -4.4274, -4.6320,  1.7017,  1.7264, -4.6289,\n",
       "          -2.2004],\n",
       "         [ 2.2061, -2.2585,  2.8221, -2.0597, -0.2349,  5.0694, -1.8953,\n",
       "           1.2239],\n",
       "         [ 2.1368,  1.2673, -0.2101,  0.4840,  2.2571,  0.3928, -3.0440,\n",
       "          -5.0011],\n",
       "         [ 1.4417, -3.8864,  1.5196, -3.0318, -2.2705, -1.7417, -4.6835,\n",
       "          -0.1759],\n",
       "         [ 0.7326,  1.1572,  4.9376, -6.6083, -0.6134,  2.1168, -3.0200,\n",
       "           1.2251],\n",
       "         [-0.5505,  0.2772,  1.8915,  6.7931,  2.9333, -2.7175, -5.6576,\n",
       "           4.5879],\n",
       "         [-3.2447,  2.1095, -5.2072,  2.5459,  2.6311, -1.2021,  1.6089,\n",
       "          -3.0549],\n",
       "         [-0.5505,  0.2772,  1.8915,  6.7931,  2.9333, -2.7175, -5.6576,\n",
       "           4.5879],\n",
       "         [-4.7788, -2.8521,  4.9142, -2.7896,  0.6033, -4.6777, -1.3862,\n",
       "          -1.7100],\n",
       "         [-0.2921, -1.1811,  0.9804, -0.3967, -1.1244, -0.4023, -0.2383,\n",
       "           0.8081],\n",
       "         [-4.5343,  2.5292, -1.6112, -1.4418, -0.9601,  5.2224, -2.0328,\n",
       "           0.3275],\n",
       "         [ 0.6133,  0.5285, -1.2731,  2.7694,  0.1875,  0.6716,  1.7348,\n",
       "           2.5242],\n",
       "         [ 0.6746, -0.5223, -2.0905,  0.9552, -0.0874,  0.5118,  2.3895,\n",
       "          -0.5861],\n",
       "         [ 1.4903, -1.9198, -0.8015,  1.3495, -4.0996,  2.9279,  0.2374,\n",
       "           5.1068],\n",
       "         [-1.0965,  9.3318, -1.6929, -1.6007, -1.7494, -3.7402,  1.2597,\n",
       "           3.0292],\n",
       "         [-1.7908,  1.2878,  1.7415, -0.1880,  4.1052,  1.7506,  1.8086,\n",
       "          -0.4078]],\n",
       "\n",
       "        [[ 5.8015,  0.2251, -0.1426, -2.4801,  0.7713,  0.4973,  0.2102,\n",
       "          -6.4981],\n",
       "         [-1.0859,  0.1397,  2.4643, -4.6394, -2.2958,  3.8204, -0.8981,\n",
       "          -0.5112],\n",
       "         [-0.2921, -1.1811,  0.9804, -0.3967, -1.1244, -0.4023, -0.2383,\n",
       "           0.8081],\n",
       "         [ 2.0418, -1.3944,  3.5376,  7.9463,  0.2721, -2.8114, -0.3941,\n",
       "           1.1258],\n",
       "         [ 0.7326,  1.1572,  4.9376, -6.6083, -0.6134,  2.1168, -3.0200,\n",
       "           1.2251],\n",
       "         [-2.2341,  1.5642,  1.0999,  5.0176,  0.8252,  2.3192, -2.1430,\n",
       "           3.1657],\n",
       "         [ 4.2105,  4.4562,  0.9855,  5.0401,  2.8744, -2.0868, -0.9742,\n",
       "           1.2223],\n",
       "         [-1.9774, -2.1304, -3.8889, -3.9449, -6.2240, -2.6995,  0.0555,\n",
       "           0.4996],\n",
       "         [-0.0453, -5.5603,  1.8929, -0.8498, -1.5823, -1.1880,  2.9468,\n",
       "          -0.7593],\n",
       "         [ 0.6735,  1.5373,  0.2960, -1.6935, -1.9504, -4.6427, -2.5472,\n",
       "          -0.7622],\n",
       "         [-4.2965,  3.5585, -4.9433,  0.1785, -0.6810,  0.0834, -4.3661,\n",
       "          -4.6913],\n",
       "         [-1.0965,  9.3318, -1.6929, -1.6007, -1.7494, -3.7402,  1.2597,\n",
       "           3.0292],\n",
       "         [-2.2435, -3.4456, -7.0729,  2.5914, -2.7787, -0.1917, -2.3160,\n",
       "          -1.4080],\n",
       "         [-4.5343,  2.5292, -1.6112, -1.4418, -0.9601,  5.2224, -2.0328,\n",
       "           0.3275],\n",
       "         [ 2.3387, -1.4267, -1.8921, -1.5710, -1.8809, -3.1779,  3.0902,\n",
       "           1.2440],\n",
       "         [-0.5633,  5.5082,  0.9964,  1.4051, -0.4789, -0.6365,  1.9125,\n",
       "           3.6248]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = InputEmbeddings(d_model, vocab_size)\n",
    "output_emb = embeddings(x)\n",
    "output_emb.shape\n",
    "output_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab3c839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = nn.Embedding(num_embeddings= vocab_size,embedding_dim=d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93f7c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [[\"i\",\"Like\",\"Math\"],[\"I\",\"Like\",\"Music\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c363cf26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 8])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e(x).shape\n",
    "(e(x) * (math.sqrt(d_model))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e808b63c-5932-45c4-945e-de5c9f9b438c",
   "metadata": {},
   "source": [
    "# Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "479c2ef6-ae91-44db-b428-a18e943f0144",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, seq_len: int, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Create a matrix of shape (seq_len, d_model)\n",
    "        pe = torch.zeros(seq_len, d_model)\n",
    "        # Create a vector of shape (seq_len)\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1) # (seq_len, 1)\n",
    "        # Create a vector of shape (d_model)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)) # (d_model / 2)\n",
    "        # Apply sine to even indices\n",
    "        pe[:, 0::2] = torch.sin(position * div_term) # sin(position * (10000 ** (2i / d_model))\n",
    "        # Apply cosine to odd indices\n",
    "        pe[:, 1::2] = torch.cos(position * div_term) # cos(position * (10000 ** (2i / d_model))\n",
    "        # Add a batch dimension to the positional encoding\n",
    "        pe = pe.unsqueeze(0) # (1, seq_len, d_model)\n",
    "        # Register the positional encoding as a buffer\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + (self.pe[:, :x.shape[1], :]).requires_grad_(False) # (batch, seq_len, d_model)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d533cc7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "        14., 15.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_emb.shape[1]\n",
    "torch.arange(0,d_model,2).float() \n",
    "torch.arange(0,seq_len,dtype=torch.float)\n",
    "torch.zeros(seq_len,d_model)\n",
    "torch.zeros(seq_len,d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce58de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PositionalEncoding(d_model=d_model,seq_len=seq_len,dropout=0.1)\n",
    "o_p_embeding = p(output_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70f19298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 8])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_p_embeding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08dee34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a1cd247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.parameter.Parameter"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1936c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self,eps: float = 10**-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.alpha = nn.Parameter(torch.ones(1))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        mean = x.mean(dim = -1,keepdim=True)\n",
    "        std = x.std(dim = -1,keepdim=True)\n",
    "        x = self.alpha*(x- mean)/(std+ self.eps) + self.bias \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec189192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(1)\n",
    "torch.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c74dc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.7178,  0.6342, -0.6251,  1.3915,  0.3598,  0.3073,  0.5444, -0.8942],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([-3.4286,  3.9512, -0.0000,  6.3274,  3.0903,  2.9257,  3.6697, -0.8442],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = LayerNormalization()\n",
    "lm(o_p_embeding)[0][0]\n",
    "o_p_embeding[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55561d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed Forward Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d30c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardBlock(nn.Module):\n",
    "    def __init__(self,d_model: int,d_ff : int , dropout : float)-> None :\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2  = nn.Linear(d_ff,d_model)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.linear_2(self.dropout(torch.relu(self.linear_1(x))))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c40608bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = FeedForwardBlock(8,12,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ace17b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 8])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l(lm(o_p_embeding)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17a90bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualConnection(nn.Module):\n",
    "    def __init__(self,features,dropout):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm = LayerNormalization(features)\n",
    "    \n",
    "    def forward(self,x,sublayer):\n",
    "        x = x+ self.dropout(sublayer(self.norm(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84e9470",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttentionBlock(nn.Module):\n",
    "    def __init__(self,d_model:int,h:int,dropout:float)->None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.h = h\n",
    "        assert d_model % h == 0, \"d_model is not divisible by h\"\n",
    "        \n",
    "        self.d_k = d_model // h # Dimension of vector seen by each head\n",
    "        self.w_q = nn.Linear(d_model, d_model, bias=False) # Wq\n",
    "        self.w_k = nn.Linear(d_model, d_model, bias=False) # Wk\n",
    "        self.w_v = nn.Linear(d_model, d_model, bias=False) # Wv\n",
    "        self.w_o = nn.Linear(d_model, d_model, bias=False) # Wo\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    @staticmethod\n",
    "    def attention(query,key,value,mask,dropout):\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "era",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
